{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IRDM_Project2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMsuaFTS/BsW4Ib/F49Ubts",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/apof/Information-Retrieval---Data-Mining-/blob/main/IRDM_Project2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9qvy-qmt-Pm",
        "outputId": "2cf4ab5f-98cb-4501-8d2e-0c038b820da7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzlwMzcmb7bw"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from IPython.display import clear_output\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXDu6NhklusF"
      },
      "source": [
        "**Load The Data and Process the with Pandas DataFrames**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQwDZDKHuH1l"
      },
      "source": [
        "train_data_file = \"drive/MyDrive/Datasets/IRDM/train_data.tsv\"\n",
        "test_data_file = \"drive/MyDrive/Datasets/IRDM/validation_data.tsv\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btO5-N2ybl2O",
        "outputId": "ea152f81-6bdb-4b6d-ceeb-2092b3ed4aa6"
      },
      "source": [
        "col_names=['qid','pid','query','passage','relevancy']\n",
        "\n",
        "train_data_init=pd.read_csv(train_data_file, sep='\\t', header=None, names=col_names)\n",
        "train_data_df=pd.DataFrame(train_data_init)\n",
        "train_data_df = train_data_df.iloc[1:]\n",
        "\n",
        "test_data_init=pd.read_csv(test_data_file, sep='\\t', header=None, names=col_names)\n",
        "test_data_df=pd.DataFrame(test_data_init)\n",
        "test_data_df = test_data_df.iloc[1:]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (0,1,4) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2182zoCaeOy0"
      },
      "source": [
        "train_data_df[\"relevancy\"] = train_data_df.relevancy.astype(float)\n",
        "test_data_df[\"relevancy\"] = test_data_df.relevancy.astype(float)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByWdiR4ehWr5"
      },
      "source": [
        "train_labels = train_data_df['relevancy'].values\n",
        "test_labels = test_data_df['relevancy'].values"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DclKom1jTXP"
      },
      "source": [
        "train_passages = train_data_df['passage'].values\n",
        "train_queries = train_data_df['query'].values\n",
        "train_pids = train_data_df['pid'].values\n",
        "train_qids = train_data_df['qid'].values"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSAxbJF1mtw8"
      },
      "source": [
        "test_passages = test_data_df['passage'].values\n",
        "test_queries = test_data_df['query'].values\n",
        "test_pids = test_data_df['pid'].values\n",
        "test_qids = test_data_df['qid'].values"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpukHGbvzKb2"
      },
      "source": [
        "**Create Dictionaries for the Training and Testing Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9soNcNQGzIFn"
      },
      "source": [
        "train_passage_dict = {}\n",
        "train_query_dict = {}\n",
        "for i, _ in enumerate(train_queries):\n",
        "  train_passage_dict[train_pids[i]] = train_passages[i]\n",
        "  train_query_dict[train_qids[i]] = train_queries[i]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJz1sCG433R8"
      },
      "source": [
        "test_passage_dict = {}\n",
        "test_query_dict = {}\n",
        "for i, _ in enumerate(test_queries):\n",
        "  test_passage_dict[test_pids[i]] = test_passages[i]\n",
        "  test_query_dict[test_qids[i]] = test_queries[i]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bx4snFI1thV0"
      },
      "source": [
        "**Correct Imbalanced Data with Negative Sampling**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-nozDa9ttqD"
      },
      "source": [
        "def collect_relevant_pids(pids,qids,relevancy):\n",
        "\n",
        "  relevancy_dict = {}\n",
        "  ## collect for each query all the relevant passages (relevant passages is the minority class)\n",
        "  ## and then sample randomply K negative examples\n",
        "\n",
        "  for i, qid in enumerate(qids):\n",
        "    if(relevancy_dict.get(qid) == None):\n",
        "      if(relevancy[i] == 0):\n",
        "        relevancy_dict[qid] = [[],[(pids[i],i)]]\n",
        "      else:\n",
        "        relevancy_dict[qid] = [[(pids[i],i)],[]]\n",
        "    else:\n",
        "      l = relevancy_dict.get(qid)\n",
        "      if(relevancy[i] == 0):\n",
        "        l[1].append((pids[i],i))\n",
        "      else:\n",
        "        l[0].append((pids[i],i))\n",
        "      relevancy_dict[qid] = l\n",
        "\n",
        "  return relevancy_dict"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_Sb4rSpvP9n"
      },
      "source": [
        "train_relevant_passages_dict = collect_relevant_pids(train_pids,train_qids,train_labels)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZa3r6YL4hpt"
      },
      "source": [
        "test_relevant_passages_dict = collect_relevant_pids(test_pids,test_qids,test_labels)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQXi92iZwCKf"
      },
      "source": [
        "def negative_sampling(relevant_passages_dict,passage_dict,query_dict,K):\n",
        "\n",
        "  sampled_passages = []\n",
        "  sampled_queries = []\n",
        "  sampled_labels = []\n",
        "  sampled_qids = []\n",
        "  sampled_pids = []\n",
        "\n",
        "\n",
        "  for key in relevant_passages_dict:\n",
        "    l = relevant_passages_dict.get(key)\n",
        "\n",
        "    number_of_positive_samples = len(l[0])\n",
        "    number_of_negative_passages = len(l[1])\n",
        "\n",
        "    #print(\"query \" + str(key) + \" has \" + str(number_of_positive_samples) + \" positive and \" + str(number_of_negative_passages) + \" negative sample\" )\n",
        "\n",
        "    ## if there are not relevant passages continue\n",
        "    if(number_of_positive_samples != 0):\n",
        "      ## collect all relevant passages\n",
        "      for (pid,_) in l[0]:\n",
        "        sampled_queries.append(query_dict.get(key))\n",
        "        sampled_passages.append(passage_dict.get(pid))\n",
        "        sampled_labels.append(1)\n",
        "        sampled_qids.append(key)\n",
        "        sampled_pids.append(pid)\n",
        "\n",
        "      negative_examples_to_draw = None\n",
        "      ## if the positive examples for a query are more than the negative one --> select all the negative and add them to the dataset\n",
        "      if(number_of_positive_samples >= number_of_negative_passages):\n",
        "        negative_examples_to_draw = number_of_negative_passages\n",
        "      else:\n",
        "        ## if there are more negative examples than K\n",
        "        if(number_of_negative_passages >= K):\n",
        "          negative_examples_to_draw = K\n",
        "        else:\n",
        "          ## elese collect all the negaative examples\n",
        "          negative_examples_to_draw = number_of_positive_samples\n",
        "\n",
        "      ## select a number of negative samples equal to the number of the positive ones\n",
        "      indexes = random.sample(range(0,number_of_negative_passages), negative_examples_to_draw)\n",
        "\n",
        "      for i in indexes:\n",
        "        sampled_queries.append(query_dict.get(key))\n",
        "        sampled_passages.append(passage_dict.get(l[1][i][0]))\n",
        "        sampled_labels.append(-1)\n",
        "        sampled_qids.append(key)\n",
        "        sampled_pids.append(l[1][i][0])\n",
        "\n",
        "  print(len(sampled_labels))\n",
        "\n",
        "  return sampled_passages, sampled_queries, sampled_labels, sampled_pids, sampled_qids\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sLnaKNvpGDL"
      },
      "source": [
        "## how many negative samples to collect for each positive one\n",
        "K = 5"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEc_zfRh3LLJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5ef7131-855d-48bd-83ef-de5c81028232"
      },
      "source": [
        "sampled_passages, sampled_queries, sampled_labels, sampled_pids, sampled_qids = negative_sampling(train_relevant_passages_dict,train_passage_dict,train_query_dict,K)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "27713\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJqIp_P-PZWX",
        "outputId": "f8dd88b3-ce9d-4000-95d0-3c1dc331cf3f"
      },
      "source": [
        "SAMPLE_TEST = True\n",
        "if(SAMPLE_TEST == True):\n",
        "  K = 100\n",
        "  sampled_test_passages, sampled_test_queries, sampled_test_labels, sampled_test_pids, sampled_test_qids = negative_sampling(test_relevant_passages_dict,test_passage_dict,test_query_dict,K)\n",
        "  test_relevant_passages_dict  = collect_relevant_pids(sampled_test_pids,sampled_test_qids,sampled_test_labels)\n",
        "  test_passages = sampled_test_passages\n",
        "  test_queries = sampled_test_queries\n",
        "  test_labels = sampled_test_labels"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113142\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--3xlr03ogL0"
      },
      "source": [
        "**Evaluation Metrics Mean Precision and NDCG**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCZ7CeUbEElT"
      },
      "source": [
        "def Average_Precision(predictions,test_labels,test_query_dict,test_relevant_passages_dict):\n",
        "\n",
        "  average_precision = 0\n",
        "  queries_num = 0\n",
        "\n",
        "  for key in test_query_dict:\n",
        "    \n",
        "    relevant_docs = test_relevant_passages_dict.get(key)[0]\n",
        "    irrelevant_docs = test_relevant_passages_dict.get(key)[1]\n",
        "    if(len(relevant_docs) != 0):\n",
        "      queries_num += 1\n",
        "      ### based on all the candidate passages create a list with tuples (ranking,label)\n",
        "      #print(str(key) + \" \" + str(len(relevant_docs)) + \"  \" + str(len(irrelevant_docs)))\n",
        "      ranking_list = []\n",
        "      for (_,index) in relevant_docs + irrelevant_docs:\n",
        "        ranking = None\n",
        "        if(predictions[index] == None):\n",
        "          ranking = 0\n",
        "        else:\n",
        "          ranking = predictions[index]\n",
        "        ranking_list.append((ranking,test_labels[index]))\n",
        "      ## get the top 100 docs\n",
        "      sorted_ranking = sorted(ranking_list, key=lambda tup: tup[0], reverse = True)\n",
        "      sorted_ranking = sorted_ranking[0:100]\n",
        "      indx = 1\n",
        "      precision = []\n",
        "      relevant_docs_found = 0\n",
        "      for (_,label) in sorted_ranking:\n",
        "        if(label == 1):\n",
        "          #print(\"relevant doc ranked  at \" + str(indx))\n",
        "          relevant_docs_found += 1\n",
        "        precision.append(relevant_docs_found/indx)\n",
        "        indx += 1\n",
        "      query_precision = np.sum(np.array(precision))/len(sorted_ranking)\n",
        "      #print(\"Precision for query \" + str(key) + \" is \" + str(query_precision))\n",
        "\n",
        "      average_precision += query_precision\n",
        "\n",
        "  print(\"Average Precision: \" + str(average_precision/queries_num))   "
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04iSGWEukwYr"
      },
      "source": [
        "def Average_NDCG(predictions,test_labels,test_query_dict,test_relevant_passages_dict):\n",
        "\n",
        "  average_ndcg = 0\n",
        "  queries_num = 0\n",
        "\n",
        "  for key in test_query_dict:\n",
        "    relevant_docs = test_relevant_passages_dict.get(key)[0]\n",
        "    irrelevant_docs = test_relevant_passages_dict.get(key)[1]\n",
        "    if(len(relevant_docs) != 0):\n",
        "\n",
        "      queries_num += 1\n",
        "\n",
        "      ## compute IDCG\n",
        "      IDCG = 0\n",
        "      for i in range(len(relevant_docs)):\n",
        "        IDCG += 1/(np.log2((i+1)+1))\n",
        "\n",
        "      ranking_list = []\n",
        "      for (_,index) in relevant_docs + irrelevant_docs:\n",
        "        ranking = None\n",
        "        if(predictions[index] == None):\n",
        "          ranking = 0\n",
        "        else:\n",
        "          ranking = predictions[index]\n",
        "        ranking_list.append((ranking,test_labels[index]))\n",
        "      ## get the top 100 docs\n",
        "      sorted_ranking = sorted(ranking_list, key=lambda tup: tup[0], reverse = True)\n",
        "      sorted_ranking = sorted_ranking[0:100]\n",
        "\n",
        "      ## compute DCG\n",
        "      DCG = 0\n",
        "      for i,(_,label) in enumerate(sorted_ranking):\n",
        "        if(label == 1):\n",
        "          DCG += 1/(np.log2((i+1)+1))\n",
        "\n",
        "      average_ndcg += DCG/IDCG\n",
        "\n",
        "  print(\"Average NDCG: \" + str(average_ndcg/queries_num))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "np3wW8e3STW6"
      },
      "source": [
        "**BM25 Retrieval Method**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9rxnFZ7SStq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c04ff423-2f4a-4082-ddcf-3a0eb3465aa0"
      },
      "source": [
        "## immport useful utilities from previous coursework\n",
        "import sys\n",
        "sys.path.insert(0,'drive/MyDrive/Src/')\n",
        "import Utils\n",
        "import RetrievalMethods"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkgvjUYkS03y"
      },
      "source": [
        "preprocessed_queries_dict = Utils.preprocess_queries(test_query_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlQYr2YwV11B"
      },
      "source": [
        "## create candidate passage dict\n",
        "def get_candidate_passages(test_relevant_passages_dict):\n",
        "  index_dict = {}\n",
        "  query_passage_dict ={}\n",
        "  for key in test_relevant_passages_dict:\n",
        "    l = test_relevant_passages_dict.get(key)\n",
        "    for (pid,ind) in l[0] + l[1]:\n",
        "      if(query_passage_dict.get(key) == None):\n",
        "        query_passage_dict[key] = [pid]\n",
        "      else:\n",
        "        query_passage_dict[key].append(pid)\n",
        "      index_dict[(key,pid)] = ind\n",
        "\n",
        "  return query_passage_dict, index_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xARYfyHdW_lQ"
      },
      "source": [
        "query_passage_dict, index_dict = get_candidate_passages(test_relevant_passages_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDuGe7gvVkS5"
      },
      "source": [
        "preprocessed_passages, passage_ids, preprocessed_candidates_dict = Utils.preprocess_passages(877810,test_passage_dict,query_passage_dict,'query')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMWDBRtRZi92"
      },
      "source": [
        "inverted_index, index_token_dictionary = Utils.inverted_index(preprocessed_passages,passage_ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDODzaBJahNR"
      },
      "source": [
        "def get_BM25_score(queries_dict,passages_dict,query_passage_dict):\n",
        "  results_dict = {}\n",
        "  i = 0\n",
        "  for key in queries_dict:\n",
        "    i+=1\n",
        "    print(\"Processing query: \" + str(i)+'/'+str(len(queries_dict)))\n",
        "    clear_output(wait=True)      \n",
        "    preprocessed_passages, passage_ids, preprocessed_candidates_dict = Utils.preprocess_passages(key,passages_dict,query_passage_dict,'query')\n",
        "    inverted_index, token_index_dictionary = Utils.inverted_index(preprocessed_passages,passage_ids)\n",
        "    ranking = RetrievalMethods.BM25_Model(key,queries_dict,inverted_index,preprocessed_candidates_dict)\n",
        "    for (pid,score) in ranking:\n",
        "      results_dict[(key,pid)] = score\n",
        "\n",
        "  return results_dict\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATQPL06ZbMVk",
        "outputId": "19e3770f-7c51-4842-9d44-e5a759c8f36f"
      },
      "source": [
        "results_dict = get_BM25_score(preprocessed_queries_dict,test_passage_dict,query_passage_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing query: 2292/2292\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nd7cA-M2cTZU"
      },
      "source": [
        "predictions = []\n",
        "for i,qid in enumerate(test_qids):\n",
        "  predictions.append(results_dict.get((qid,test_pids[i])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRRvVrpwdqle",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7028b1a-4f85-4ea4-d0c5-a3e0b873f5e7"
      },
      "source": [
        "Average_Precision(predictions,test_labels,test_query_dict,test_relevant_passages_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average Precision: 0.022834793288548517\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJTbzmE3dvPr",
        "outputId": "9e333c42-d7a4-49e5-8016-4ffdb79dd3c4"
      },
      "source": [
        "Average_NDCG(predictions,test_labels,test_query_dict,test_relevant_passages_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average NDCG: 0.3118983295937294\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYDdJnfsnlaQ"
      },
      "source": [
        "**Preprocess Data and data Modeling for ML Ranking Methods**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBmEm2R_oL-w",
        "outputId": "72c93a52-19e1-42a2-b685-ac43e5ef5243"
      },
      "source": [
        "import joblib\n",
        "from IPython.display import clear_output\n",
        "import numpy as np\n",
        "import re\n",
        "import gensim\n",
        "from gensim.models import KeyedVectors\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import  WordNetLemmatizer\n",
        "from nltk.stem import PorterStemmer \n",
        "from nltk.tokenize import RegexpTokenizer"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CC1oGrD75zr"
      },
      "source": [
        "EMBEDDING_SIZE = 300"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc4RW-o2n_9n",
        "outputId": "3df15ecf-fafd-433c-93c5-31819ad07dac"
      },
      "source": [
        "!wget -P /root/input/ -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-18 19:18:31--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.99.222\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.99.222|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1647046227 (1.5G) [application/x-gzip]\n",
            "Saving to: ‘/root/input/GoogleNews-vectors-negative300.bin.gz’\n",
            "\n",
            "GoogleNews-vectors- 100%[===================>]   1.53G  46.0MB/s    in 35s     \n",
            "\n",
            "2021-04-18 19:19:06 (45.3 MB/s) - ‘/root/input/GoogleNews-vectors-negative300.bin.gz’ saved [1647046227/1647046227]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAiZeCynoF9n"
      },
      "source": [
        "EMBEDDING_FILE = '/root/input/GoogleNews-vectors-negative300.bin.gz'\n",
        "word2vec = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3p8VdP2q4ogG"
      },
      "source": [
        "def process_data(data,rm_stopwords = True, lemm = True):\n",
        "\tstop_words = set(stopwords.words('english'))\n",
        "\t## remove punctuation\n",
        "\ttokenizer = RegexpTokenizer(r'\\w+')\n",
        "\tprocessed_sentences = []\n",
        "\tfor sentence in data:\n",
        "\t\t## tokenise each sentence\n",
        "\t\ttokenised_sentence = tokenizer.tokenize(sentence)\n",
        "\t\t##convert to lower case\n",
        "\t\tsentence = [w.lower() for w in tokenised_sentence]\n",
        "\t\t##exclude non alphabetic words\n",
        "\t\tonly_alpha_sentence = [word for word in sentence if word.isalpha()]\n",
        "\t\t## remove stop words\n",
        "\t\tif(rm_stopwords == True):\n",
        "\t\t\tfiltered_sentence = [w for w in only_alpha_sentence if not w in stop_words]\n",
        "\t\telse:\n",
        "\t\t\tfiltered_sentence = only_alpha_sentence\n",
        "\t\tlemmatized_sentence = []\n",
        "\t\tif(lemm == True):\n",
        "\t\t\t## stemming\n",
        "\t\t\tlemmatizer = WordNetLemmatizer()\n",
        "\t\t\t#stemmer = PorterStemmer()\n",
        "\t\t\tfor word in filtered_sentence:\n",
        "\t\t\t\tlemmatized_sentence.append(lemmatizer.lemmatize(word))\n",
        "\t\t\t\t#lemmatized_sentence.append(stemmer.stem(word))\n",
        "\t\telse:\n",
        "\t\t\tlemmatized_sentence = filtered_sentence\n",
        "\n",
        "\t\tprocessed_sentences.append(lemmatized_sentence)\n",
        "\treturn processed_sentences"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knvZjgioo0Nc"
      },
      "source": [
        "train_passages = process_data(sampled_passages)\n",
        "train_queries = process_data(sampled_queries)\n",
        "test_passages = process_data(test_passages)\n",
        "test_queries = process_data(test_queries)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cRqgIdl6nDW",
        "outputId": "9292ebfd-2559-4eb6-c1a6-481498b69f6d"
      },
      "source": [
        "print(len(train_passages))\n",
        "print(len(train_queries))\n",
        "\n",
        "print(len(test_passages))\n",
        "print(len(test_queries))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "27713\n",
            "27713\n",
            "113142\n",
            "113142\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gcfd6e3pXAXO",
        "outputId": "e557dc19-70e5-4e14-ad35-03fd206dd62b"
      },
      "source": [
        "max_l = 0\n",
        "for sentence in train_passages:\n",
        "  if(len(sentence) > max_l):\n",
        "    max_l = len(sentence)\n",
        "for sentence in train_queries:\n",
        "  if(len(sentence) > max_l):\n",
        "    max_l = len(sentence)\n",
        "for sentence in test_passages:\n",
        "  if(len(sentence) > max_l):\n",
        "    max_l = len(sentence)\n",
        "for sentence in test_queries:\n",
        "  if(len(sentence) > max_l):\n",
        "    max_l = len(sentence)\n",
        "print(max_l)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "123\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPx8SdpoXk-o"
      },
      "source": [
        "def find_unique_words(datasets):\n",
        "\n",
        "  # words to indexes\n",
        "  vocab_words = {}\n",
        "  # indexes to embeddings\n",
        "  vocab_embeddings = {}\n",
        "\n",
        "  unique_words = 0\n",
        "\n",
        "  # for every data set training validation testing\n",
        "  for dataset in datasets:\n",
        "    # for every sentence\n",
        "    for sentence in dataset:\n",
        "      # for each word of the sentence\n",
        "      for word in sentence:\n",
        "        # if this word is not saved on the dictionary\n",
        "        if(vocab_words.get(word)==None):\n",
        "          # if this word exists is the word Word2Vec model\n",
        "          if word in word2vec:\n",
        "            unique_words += 1\n",
        "            vocab_words[word] = unique_words\n",
        "            vocab_embeddings[unique_words] = word2vec.wv[word]\n",
        "\n",
        "  return vocab_words,vocab_embeddings"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwTVq4HaXTBX",
        "outputId": "642340cc-d863-4d64-f689-99bc865b6c02"
      },
      "source": [
        "## vocab dict --> key each unique word and value a unique id\n",
        "## embeddings dict --> key the unique id of a word and value the respective embedding\n",
        "vocab_dict,vocab_embeddings_dict = find_unique_words([train_passages,train_queries,test_passages,test_queries])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnLQNYDRFFmK"
      },
      "source": [
        "**Model Data for the Logistic Regression and the XGBOOST**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5el6sTEm1s8o"
      },
      "source": [
        "def get_average_sentence_representation(vocab_dict,vocab_embeddings_dict,sentences):\n",
        "  representations = []\n",
        "  ## for every sentence\n",
        "  for sentence in sentences:\n",
        "    sentence_representation = []\n",
        "    for word in sentence:\n",
        "      ## collect all the word embeddings of the respective words of a sentence\n",
        "      word_index = vocab_dict.get(word)\n",
        "      if(word_index!=None):\n",
        "        word_embedding = vocab_embeddings_dict.get(word_index)\n",
        "        sentence_representation.append(np.array(word_embedding))\n",
        "      else:\n",
        "        sentence_representation.append(np.array(np.zeros(EMBEDDING_SIZE)))\n",
        "    if(len(sentence_representation) == 0):\n",
        "      sentence_representation.append(np.array(np.zeros(EMBEDDING_SIZE)))\n",
        "    sentence_representation = np.array(sentence_representation)\n",
        "\n",
        "    representations.append(np.mean(sentence_representation,axis = 0))\n",
        "\n",
        "  return np.array(representations)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pv20wAJO34tJ"
      },
      "source": [
        "train_passage_represenations = get_average_sentence_representation(vocab_dict,vocab_embeddings_dict,train_passages)\n",
        "train_queries_represenations = get_average_sentence_representation(vocab_dict,vocab_embeddings_dict,train_queries)\n",
        "\n",
        "test_passage_represenations = get_average_sentence_representation(vocab_dict,vocab_embeddings_dict,test_passages)\n",
        "test_queries_represenations = get_average_sentence_representation(vocab_dict,vocab_embeddings_dict,test_queries)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTeibggV6cdi",
        "outputId": "50a7b40a-65ee-4645-e113-3df16b7bf9ba"
      },
      "source": [
        "print(train_passage_represenations.shape)\n",
        "print(train_queries_represenations.shape)\n",
        "\n",
        "print(test_passage_represenations.shape)\n",
        "print(test_queries_represenations.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(27713, 300)\n",
            "(27713, 300)\n",
            "(1103039, 300)\n",
            "(1103039, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6LKo-hg-bIv"
      },
      "source": [
        "def combine_representations(q_rep,p_rep,flag = 'diff'):\n",
        "  representation = []\n",
        "  for i,p in enumerate(p_rep):\n",
        "    if(flag == 'diff'):\n",
        "      representation.append((p - q_rep[i])**2)\n",
        "    else:\n",
        "      representation.append(np.concatenate((p,q_rep[i]),axis = 0))\n",
        "  return np.array(representation)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eb4lB_qq_jvX"
      },
      "source": [
        "train_inputs = combine_representations(train_queries_represenations,train_passage_represenations,flag = 'diff')\n",
        "\n",
        "test_inputs = combine_representations(test_queries_represenations,test_passage_represenations,flag = 'diff')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lHn7b3bE29y",
        "outputId": "981331ea-ec78-41e8-aa5e-4acc2107f54b"
      },
      "source": [
        "print(train_inputs.shape)\n",
        "print(train_labels.shape)\n",
        "print(test_inputs.shape)\n",
        "print(test_labels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(27713, 300)\n",
            "(4364339,)\n",
            "(1103039, 300)\n",
            "(1103039,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4eSJ6VQ-Xm9",
        "outputId": "61ac2b92-41eb-4b28-f087-dd02b05f982f"
      },
      "source": [
        "joblib.dump(train_inputs, 'drive/MyDrive/Vectors/train_inputs')\n",
        "joblib.dump(test_inputs, 'drive/MyDrive/Vectors/test_inputs')\n",
        "\n",
        "joblib.dump(sampled_labels, 'drive/MyDrive/Vectors/train_labels')\n",
        "joblib.dump(test_labels, 'drive/MyDrive/Vectors/test_labels')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['drive/MyDrive/Vectors/test_labels']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWpJOlQADS4a"
      },
      "source": [
        "**Modeling Data for the Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggeDW10ai7TG"
      },
      "source": [
        "def create_look_up_table(embeddings_dict):\n",
        "\n",
        "  look_up_table = [np.zeros(300)]\n",
        "  for key in sorted (embeddings_dict.keys()) :  \n",
        "     look_up_table.append(embeddings_dict.get(key))\n",
        "  return np.array(look_up_table) "
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CswOXpUFgklJ"
      },
      "source": [
        "def padding_at_the_end_V2(max_length,vector):\n",
        "\n",
        "  vector = np.array(vector)\n",
        "\n",
        "  if(vector.shape[0] < max_length and vector.shape[0] != 0):\n",
        "    padding_vector = np.zeros(max_length - vector.shape[0])\n",
        "    return np.concatenate((vector, padding_vector), axis=0)\n",
        "  elif(vector.shape[0] == max_length):\n",
        "    return vector\n",
        "  else:\n",
        "    return np.zeros((0,0))"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdGwycxbbcIH"
      },
      "source": [
        "def convert_to_embeddings_V2(data,max_length,labels,vocab_words):\n",
        "\n",
        "  embedding_list = []\n",
        "  embedding_labels = []\n",
        "  lengths = []\n",
        "  count = -1\n",
        "\n",
        "  for sentence in data:\n",
        "    count += 1\n",
        "    embedding_sentence = []\n",
        "    for word in sentence:\n",
        "      if(vocab_words.get(word)!=None):\n",
        "        #word_one_hot_encoding = np.zeros(len(vocab_words))\n",
        "        #word_one_hot_encoding[vocab_words.get(word)] = 1\n",
        "        embedding_sentence.append(vocab_words.get(word))\n",
        "\n",
        "    if(len(embedding_sentence) == 0):\n",
        "      lengths.append(2)\n",
        "    else:\n",
        "      lengths.append(len(embedding_sentence))\n",
        "\n",
        "    embedding_sentence =  padding_at_the_end_V2(max_length,embedding_sentence) \n",
        "\n",
        "    if(embedding_sentence.shape[0]!=0):\n",
        "      embedding_labels.append(labels[count])\n",
        "      embedding_list.append(np.array(embedding_sentence))\n",
        "    else:\n",
        "      embedding_labels.append(labels[count])\n",
        "      #random_embed = np.zeros(max_length)\n",
        "      #random_embed[0] = 1\n",
        "      embedding_list.append(np.zeros(max_length))\n",
        "  \n",
        "  return np.array(embedding_list),np.array(embedding_labels),np.array(lengths)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1U_3wfjDamO"
      },
      "source": [
        "train_inputs_passages,train_labels,train_passages_lengths = convert_to_embeddings_V2(train_passages,max_l,sampled_labels,vocab_dict)\n",
        "train_inputs_queries,_,train_queries_lengths = convert_to_embeddings_V2(train_queries,max_l,sampled_labels,vocab_dict)\n",
        "\n",
        "test_inputs_passages,test_labels, test_passages_lengths = convert_to_embeddings_V2(test_passages,max_l,test_labels,vocab_dict)\n",
        "test_inputs_queries,_, test_queries_lengths = convert_to_embeddings_V2(test_queries,max_l,test_labels,vocab_dict)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJiWlP46EvDT",
        "outputId": "ac711a8a-bc4a-49fe-dcac-a5684992ab66"
      },
      "source": [
        "print(train_inputs_passages.shape)\n",
        "print(train_inputs_queries.shape)\n",
        "\n",
        "print(test_inputs_passages.shape)\n",
        "print(test_inputs_queries.shape)\n",
        "\n",
        "print(train_passages_lengths.shape)\n",
        "print(train_queries_lengths.shape)\n",
        "print(test_passages_lengths.shape)\n",
        "print(test_queries_lengths.shape)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(27713, 123)\n",
            "(27713, 123)\n",
            "(113142, 123)\n",
            "(113142, 123)\n",
            "(27713,)\n",
            "(27713,)\n",
            "(113142,)\n",
            "(113142,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMoosUy8jes2",
        "outputId": "8e39a8b5-1c71-425c-8af1-d89a03e1874a"
      },
      "source": [
        "look_up_table = create_look_up_table(vocab_embeddings_dict)\n",
        "print(look_up_table.shape)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(53806, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adwNMtVXK2jw",
        "outputId": "08f5ea30-f1a2-40aa-b476-423375477163"
      },
      "source": [
        "joblib.dump(train_inputs_passages, 'drive/MyDrive/Vectors/train_inputs_passages')\n",
        "joblib.dump(train_inputs_queries, 'drive/MyDrive/Vectors/train_inputs_queries')\n",
        "\n",
        "joblib.dump(test_inputs_passages, 'drive/MyDrive/Vectors/test_inputs_passages')\n",
        "joblib.dump(test_inputs_queries, 'drive/MyDrive/Vectors/test_inputs_queries')\n",
        "\n",
        "joblib.dump(train_passages_lengths, 'drive/MyDrive/Vectors/train_passages_lengths')\n",
        "joblib.dump(train_queries_lengths, 'drive/MyDrive/Vectors/train_queries_lengths')\n",
        "joblib.dump(test_passages_lengths, 'drive/MyDrive/Vectors/test_passages_lengths')\n",
        "joblib.dump(test_queries_lengths, 'drive/MyDrive/Vectors/test_queries_lengths')\n",
        "\n",
        "joblib.dump(look_up_table, 'drive/MyDrive/Vectors/look_up_table')\n",
        "\n",
        "joblib.dump(test_labels, 'drive/MyDrive/Vectors/test_labels')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['drive/MyDrive/Vectors/test_labels']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f76oWE8w2Khr"
      },
      "source": [
        "**Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7Wgg21VCfJA"
      },
      "source": [
        "train_inputs = joblib.load('drive/MyDrive/Vectors/train_inputs')\n",
        "train_labels = np.array(joblib.load('drive/MyDrive/Vectors/train_labels'))\n",
        "test_inputs = joblib.load('drive/MyDrive/Vectors/test_inputs')\n",
        "test_labels = joblib.load('drive/MyDrive/Vectors/test_labels')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThqP5Yv6FlDW",
        "outputId": "123a4a98-64fd-41c5-ff50-c0e51b5b3cc3"
      },
      "source": [
        "print(train_inputs.shape)\n",
        "print(train_labels.shape)\n",
        "print(test_inputs.shape)\n",
        "print(test_labels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(27713, 300)\n",
            "(27713,)\n",
            "(1103039, 300)\n",
            "(1103039,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SI4CKPXZ6yyN"
      },
      "source": [
        "def predict(w,xTr):\n",
        "  return xTr@w"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7J9iGOa2O5E"
      },
      "source": [
        "def logistic(w,xTr,yTr):\n",
        "\n",
        "    n, d = xTr.shape\n",
        "    ## compute the logistic loss\n",
        "    loss = 0\n",
        "    for i in range(0,n):\n",
        "        loss += np.log(1 + np.exp(-yTr[i] * w.dot(xTr[i])))\n",
        "\n",
        "    ## compute the gradient\n",
        "    grad = np.zeros((d))\n",
        "    \n",
        "    for i in range(0,n):\n",
        "        term1 = (1/(1 + np.exp(-yTr[i] * w.dot(xTr[i]))))\n",
        "        term2 = np.exp(-yTr[i] * w.dot(xTr[i]))\n",
        "        term3 = (-yTr[i] * xTr[i])      \n",
        "        grad_term = term1 * term2 * term3       \n",
        "        grad  = np.add(grad,grad_term)\n",
        "                   \n",
        "    return loss, grad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhQ8QLi05KkB"
      },
      "source": [
        "def grad_descent(func,w,alpha,maxiter,tol=1e-02):\n",
        "    \n",
        "    losses = []\n",
        "    eps = 1e-06\n",
        "    G_matrix = np.zeros((w.shape[0],w.shape[0]))\n",
        "    \n",
        "    iter_num = 0\n",
        "    criterion = True\n",
        "    \n",
        "    while(iter_num < maxiter and criterion == True):\n",
        "        iter_num += 1\n",
        "        \n",
        "        loss, gradient = func(w)\n",
        "        print(\"Iteration: \" + str(iter_num) + \" with loss \" + str(loss))\n",
        "        clear_output(wait=True)      \n",
        "        for i in range(w.shape[0]):\n",
        "            G_matrix[i][i] += gradient[i]**2\n",
        "        for i in range(w.shape[0]):\n",
        "            w[i] -= alpha*gradient[i]\n",
        "        losses.append(loss)\n",
        "        if(np.linalg.norm(gradient) < tol):\n",
        "            criterion = False\n",
        "        \n",
        "    return w, losses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqmWMIAd5qJD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "442fe8b9-1ebd-4eab-85bf-ba43b1087d85"
      },
      "source": [
        "_, d = train_inputs.shape\n",
        "w, losses = grad_descent(lambda weight: logistic(weight, train_inputs, train_labels), np.random.rand(d), 0.0001, 500)\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.semilogy(losses, c='r', linestyle='-')\n",
        "plt.xlabel(\"gradient updates\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.title(\"Adagrad convergence\")\n",
        "print(\"Final train loss: %f\" % losses[-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Final train loss: 13047.939240\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaSOI8rstNFE"
      },
      "source": [
        "predictions = predict(w,test_inputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AHaC7J7FDn9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f1084ac-1601-4e30-94fe-04f52c3c006e"
      },
      "source": [
        "Average_Precision(predictions,test_labels,test_query_dict,test_relevant_passages_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average Precision: 0.014498130966629537\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peCOKw21pBDH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bf25406-d667-4429-e530-6270de386981"
      },
      "source": [
        "Average_NDCG(predictions,test_labels,test_query_dict,test_relevant_passages_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average NDCG: 0.20629537502588136\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXyv8QxIY714"
      },
      "source": [
        "**XGBOOST with LambdaMART**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kd0CCJy7hhCf"
      },
      "source": [
        "import xgboost as xgb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELq6QnqOa0H0"
      },
      "source": [
        "def collect_group_ids_1(sampled_qids):\n",
        "\n",
        "  number_list = []\n",
        "  helper_dict = {}\n",
        "\n",
        "  for i in range(len(sampled_qids)):\n",
        "    if(helper_dict.get(sampled_qids[i]) == None):\n",
        "      helper_dict[sampled_qids[i]] = 1\n",
        "    else:\n",
        "      v = helper_dict.get(sampled_qids[i]) + 1\n",
        "      helper_dict[sampled_qids[i]] = v\n",
        "\n",
        "  for key in helper_dict:\n",
        "    number_list.append(helper_dict.get(key))\n",
        "      \n",
        "  return number_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EhW90rIccr1"
      },
      "source": [
        "train_groupd_ids = collect_group_ids_1(sampled_qids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qYK8UXScuj2"
      },
      "source": [
        "def collect_group_ids_2(test_relevant_passages_dict):\n",
        "  number_list = []\n",
        "\n",
        "  for key in test_relevant_passages_dict:\n",
        "    passages = test_relevant_passages_dict.get(key)\n",
        "    number_list.append(len(passages[0]) + len(passages[1]))\n",
        "\n",
        "  return number_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZiMLDxodK0d"
      },
      "source": [
        "test_group_ids = collect_group_ids_2(test_relevant_passages_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ivsg1TunhjPz"
      },
      "source": [
        "model = xgb.XGBRanker(  \n",
        "    tree_method='gpu_hist',\n",
        "    booster='gbtree',\n",
        "    objective='rank:pairwise',\n",
        "    random_state=42, \n",
        "    learning_rate=0.1,\n",
        "    colsample_bytree=0.9, \n",
        "    eta=0.05, \n",
        "    max_depth=4, \n",
        "    n_estimators=500, \n",
        "    subsample=0.5 \n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VQN682ihoVc"
      },
      "source": [
        "model = model.fit(train_inputs, sampled_labels, group=train_groupd_ids, verbose=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQ8Gh-0Dp_YM"
      },
      "source": [
        "def get_XGBoost_predictions(model,test_relevant_passages_dict,test_inputs):\n",
        "\n",
        "  result = []\n",
        "\n",
        "  index = 1\n",
        "  for key in test_relevant_passages_dict:\n",
        "    l = test_relevant_passages_dict.get(key)\n",
        "    group_input = []\n",
        "    indexes = []\n",
        "    for (_,i) in l[0] + l[1]:\n",
        "      indexes.append(i)\n",
        "      group_input.append(test_inputs[i])\n",
        "    group_input = np.array(group_input)\n",
        "    #print(group_input.shape)\n",
        "    preds = model.predict(group_input)\n",
        "    for i in range(len(indexes)):\n",
        "      result.append((indexes[i],preds[i]))\n",
        "\n",
        "  ## reorder the predictions\n",
        "  result = sorted(result, key=lambda tup: tup[0], reverse = False)\n",
        "\n",
        "  final_result = []\n",
        "  for (_,p) in result:\n",
        "    final_result.append(p)\n",
        "\n",
        "  return final_result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BWdjHk_rHj0"
      },
      "source": [
        "predictions = get_XGBoost_predictions(model,test_relevant_passages_dict,test_inputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbviRlqIdf9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f11e614-09a9-434b-c27d-c315c39ae28b"
      },
      "source": [
        "Average_Precision(predictions,test_labels,test_query_dict,test_relevant_passages_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average Precision: 0.012738036138242988\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akiDlySldtWs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30842747-9c33-429a-f40f-595ae21ae564"
      },
      "source": [
        "Average_NDCG(predictions,test_labels,test_query_dict,test_relevant_passages_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average NDCG: 0.17737927212459903\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCby9E6ZLiE_"
      },
      "source": [
        "**Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrzJr7AE-hx5"
      },
      "source": [
        "import joblib\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import joblib\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BuH6uHnLhdO"
      },
      "source": [
        "train_passages = joblib.load('drive/MyDrive/Vectors/train_inputs_passages')\n",
        "train_queries = joblib.load('drive/MyDrive/Vectors/train_inputs_queries')\n",
        "test_passages = joblib.load('drive/MyDrive/Vectors/test_inputs_passages')\n",
        "test_queries = joblib.load('drive/MyDrive/Vectors/test_inputs_queries')\n",
        "\n",
        "train_labels = np.array(joblib.load('drive/MyDrive/Vectors/train_labels'))\n",
        "test_labels = joblib.load('drive/MyDrive/Vectors/test_labels')\n",
        "\n",
        "look_up_table = joblib.load('drive/MyDrive/Vectors/look_up_table')\n",
        "\n",
        "train_passages_lengths = joblib.load('drive/MyDrive/Vectors/train_passages_lengths')\n",
        "train_queries_lengths = joblib.load('drive/MyDrive/Vectors/train_queries_lengths')\n",
        "test_passages_lengths = joblib.load('drive/MyDrive/Vectors/test_passages_lengths')\n",
        "test_queries_lengths = joblib.load('drive/MyDrive/Vectors/test_queries_lengths')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYQwZalPwT4_"
      },
      "source": [
        "train_labels[train_labels == -1] = 0\n",
        "test_labels[test_labels == -1] = 0"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUFIF88LNO-y"
      },
      "source": [
        "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkhGzVCx3bGP"
      },
      "source": [
        "device = 'cpu'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZN5zdGdH2e1"
      },
      "source": [
        "train_passages_data = torch.from_numpy(train_passages).int().to(device)\n",
        "train_queries_data = torch.from_numpy(train_queries).int().to(device)\n",
        "\n",
        "train_passages_lengths = torch.from_numpy(train_passages_lengths)\n",
        "train_passages_lengths = torch.as_tensor(train_passages_lengths.cpu(), dtype=torch.int64)\n",
        "\n",
        "train_queries_lengths = torch.from_numpy(train_queries_lengths)\n",
        "train_queries_lengths = torch.as_tensor(train_queries_lengths.cpu(), dtype=torch.int64)\n",
        "\n",
        "train_labels = torch.from_numpy(train_labels).to(device)\n",
        "\n",
        "look_up_table = torch.from_numpy(look_up_table).float().to(device)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UN7ZO_2XIAeO"
      },
      "source": [
        "test_passages_data = torch.from_numpy(test_passages).int().to(device)\n",
        "test_queries_data = torch.from_numpy(test_queries).int().to(device)\n",
        "\n",
        "test_passages_lengths = torch.from_numpy(test_passages_lengths)\n",
        "test_passages_lengths = torch.as_tensor(test_passages_lengths.cpu(), dtype=torch.int64)\n",
        "\n",
        "test_queries_lengths = torch.from_numpy(test_queries_lengths)\n",
        "test_queries_lengths = torch.as_tensor(test_queries_lengths.cpu(), dtype=torch.int64)\n",
        "\n",
        "test_labels = torch.from_numpy(test_labels).to(device)\n",
        "\n",
        "look_up_table = torch.from_numpy(look_up_table).float().to(device)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dApMPGmFvt5U"
      },
      "source": [
        "batch_size= 128\n",
        "train_set = torch.utils.data.TensorDataset(train_passages_data, train_passages_lengths, train_queries_data, train_queries_lengths, train_labels)\n",
        "train_set_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFXvdw8kIS2Y"
      },
      "source": [
        "batch_size = 128\n",
        "test_set = torch.utils.data.TensorDataset(test_passages_data, test_passages_lengths, test_queries_data, test_queries_lengths, test_labels)\n",
        "test_set_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZsCINYWTNT4",
        "outputId": "3100cb10-03a8-4e72-8d74-f33584cbef35"
      },
      "source": [
        "print(train_passages_data.max())\n",
        "print(train_passages_data.min())\n",
        "print(train_passages_lengths.max())\n",
        "print(train_passages_lengths.min())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(32849, device='cuda:0', dtype=torch.int32)\n",
            "tensor(0, device='cuda:0', dtype=torch.int32)\n",
            "tensor(101)\n",
            "tensor(2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6M6Gx6wSLMu",
        "outputId": "b36ceaa1-9d46-4497-881d-cbdb2a2b5c84"
      },
      "source": [
        "print(train_queries_data.max())\n",
        "print(train_queries_data.min())\n",
        "print(train_queries_lengths.max())\n",
        "print(train_queries_lengths.min())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(32869, device='cuda:0', dtype=torch.int32)\n",
            "tensor(0, device='cuda:0', dtype=torch.int32)\n",
            "tensor(15)\n",
            "tensor(1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylpTewVpJFKQ"
      },
      "source": [
        "## define a dictionary with the parameters of the Neural Network\n",
        "params_dictionary = {}\n",
        "params_dictionary['embedding_size'] = look_up_table.shape[1]\n",
        "params_dictionary['vocabulary_size'] = look_up_table.shape[0]\n",
        "params_dictionary['hidden_dim'] = 256\n",
        "params_dictionary['linear_dims'] = [128,64,32]\n",
        "params_dictionary['bidirectional'] = True\n",
        "params_dictionary['label_size'] = 2\n",
        "params_dictionary['rnn_type'] = 'LSTM'\n",
        "params_dictionary['dropout'] = 0.0\n",
        "params_dictionary['rnn_layers_num'] = 1\n",
        "params_dictionary['attention_layer'] = True\n",
        "params_dictionary['concat_layer'] = [64,32]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQobYenNgcKq"
      },
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, device,hidden_size):\n",
        "        super(Attention, self).__init__()\n",
        "        self.device = device\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.concat_linear = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size, hidden_size)\n",
        "\n",
        "        ## add this model the same same device with the RNN\n",
        "        self.to(device)\n",
        "\n",
        "    def forward(self, rnn_outputs, final_hidden_state):\n",
        "      attn_weights = self.attn(rnn_outputs) # (batch_size, seq_len, hidden_dim)\n",
        "      attn_weights = torch.bmm(attn_weights, final_hidden_state.unsqueeze(2))\n",
        "      attn_weights = F.softmax(attn_weights.squeeze(2), dim=1)\n",
        "      context = torch.bmm(rnn_outputs.transpose(1, 2), attn_weights.unsqueeze(2)).squeeze(2)\n",
        "      attn_hidden = torch.tanh(self.concat_linear(torch.cat((context, final_hidden_state), dim=1)))\n",
        "      return attn_hidden, attn_weights"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXfrPNpg6EEH"
      },
      "source": [
        "class RnnClassifier(nn.Module):\n",
        "    def __init__(self, device, params_dictionary,look_up_table):\n",
        "        super(RnnClassifier, self).__init__()\n",
        "        self.params = params_dictionary\n",
        "        self.device = device\n",
        "\n",
        "        # Calculate number of directions\n",
        "        self.num_directions = 2 if self.params.get('bidirectional') == True else 1\n",
        "\n",
        "        # define an attention model\n",
        "        # Choose attention model\n",
        "        self.attention = Attention(self.device,self.params.get('hidden_dim')* self.num_directions)\n",
        "\n",
        "        # Embedding layer (vocabulary_size X embedding_dimension)\n",
        "        self.word_embeddings = nn.Embedding.from_pretrained(look_up_table)\n",
        "\n",
        "        ## here store in a list all the dimensions of the layers rnn_output --> linear layers --> labels layer\n",
        "        self.linear_dims = [self.params.get('hidden_dim') * self.num_directions] + self.params.get('linear_dims')\n",
        "\n",
        "        # Work with LSTM cell for now\n",
        "        self.rnn = nn.LSTM\n",
        "\n",
        "        ## define the RNN layer\n",
        "        self.rnn = self.rnn(self.params.get('embedding_size'),\n",
        "                            self.params.get('hidden_dim'),\n",
        "                            num_layers=self.params.get('rnn_layers_num'),\n",
        "                            bidirectional=self.params.get('bidirectional'),\n",
        "                            dropout=float(self.params.get('dropout')),\n",
        "                            batch_first=True)\n",
        "        \n",
        "        ## the hidden state of the RNN empty for now\n",
        "        self.hidden = None\n",
        "        \n",
        "        # Define set of fully connected layers (Linear Layer + Activation Layer)\n",
        "        ## this set of layers takes the output of the RNN or the Attention layer and applies a feedforward NN on it\n",
        "        ## consecutive linear + Relu layers are applied (the final layer does not have a relu activation!)\n",
        "        self.linears = nn.ModuleList()\n",
        "        for i in range(0, len(self.linear_dims)-1):\n",
        "            if self.params.get('dropout') > 0.0:\n",
        "                self.linears.append(nn.Dropout(p=self.params.get('dropout')))\n",
        "            linear_layer = nn.Linear(self.linear_dims[i], self.linear_dims[i+1])\n",
        "            self.init_weights(linear_layer)\n",
        "            self.linears.append(linear_layer)\n",
        "            self.linears.append(nn.ReLU())\n",
        "\n",
        "        self.to(self.device)\n",
        "\n",
        "    def init_weights(self, layer):\n",
        "      if type(layer) == nn.Linear:\n",
        "        torch.nn.init.xavier_uniform_(layer.weight)\n",
        "        layer.bias.data.fill_(0.01)\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "      return (torch.zeros(self.params.get('rnn_layers_num') * self.num_directions, batch_size, self.params.get('hidden_dim')).to(self.device),\n",
        "              torch.zeros(self.params.get('rnn_layers_num') * self.num_directions, batch_size, self.params.get('hidden_dim')).to(self.device))\n",
        "      \n",
        "\n",
        "    def forward(self, inputs, X_lengths):\n",
        "        batch_size, seq_len = inputs.shape\n",
        "\n",
        "        ## Push through embedding layer\n",
        "        embedded_inputs = self.word_embeddings(inputs)\n",
        "\n",
        "        ## initialise the hidden state of the RNN\n",
        "        self.hidden = self.init_hidden(batch_size)\n",
        "\n",
        "        # pack_padded_sequence so that padded items in the sequence won't be shown to the LSTM\n",
        "        padded_X = torch.nn.utils.rnn.pack_padded_sequence(embedded_inputs, X_lengths, batch_first=True, enforce_sorted = False)\n",
        "\n",
        "        ## pass the data through the recurrent layer\n",
        "        rnn_output, self.hidden = self.rnn(padded_X, self.hidden)\n",
        "\n",
        "        # undo the packing operation\n",
        "        rnn_output_unpacked, lens_unpacked = torch.nn.utils.rnn.pad_packed_sequence(rnn_output, batch_first=True)\n",
        "\n",
        "        ## Collect last hidden state\n",
        "        final_state = self.hidden[0].view(self.params.get('rnn_layers_num'), self.num_directions, batch_size, self.params.get('hidden_dim'))[-1]\n",
        "\n",
        "        # Handle directions if more than one\n",
        "        final_hidden_state = None\n",
        "        ## in case we have only one direction\n",
        "        if self.num_directions == 1:\n",
        "            final_hidden_state = final_state.squeeze(0)\n",
        "        ## in case we have 2 directions concatenate these two states\n",
        "        elif self.num_directions == 2:\n",
        "            h_1, h_2 = final_state[0], final_state[1]\n",
        "            final_hidden_state = torch.cat((h_1, h_2), 1)  # Concatenate both states\n",
        "\n",
        "        ## Attention Layer\n",
        "        if(self.params.get('attention_layer') == False):\n",
        "          X = final_hidden_state\n",
        "        else:\n",
        "          rnn_output = rnn_output_unpacked.permute(1, 0, 2)\n",
        "          X, attention_weights = self.attention(rnn_output_unpacked, final_hidden_state)\n",
        "\n",
        "        # Push through linear layers\n",
        "        for l in self.linears:\n",
        "            X = l(X)\n",
        "\n",
        "        #print(X.shape)\n",
        "\n",
        "        #log_probs = F.log_softmax(X, dim=1)\n",
        "\n",
        "        #print(log_probs.shape)\n",
        "\n",
        "        return X"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0T168J2YDYCz"
      },
      "source": [
        "class RankingModel(nn.Module):\n",
        "\n",
        "  def __init__(self, device, params_dictionary,look_up_table):\n",
        "        super(RankingModel, self).__init__()\n",
        "        self.params = params_dictionary\n",
        "        self.device = device\n",
        "\n",
        "        self.passage_network = RnnClassifier(device,params_dictionary,look_up_table)\n",
        "        self.query_network = RnnClassifier(device,params_dictionary,look_up_table)\n",
        "\n",
        "        self.linear_dims = [self.params.get('linear_dims')[-1]*2] + self.params.get('concat_layer')\n",
        "        self.linear_dims.append(self.params.get('label_size'))\n",
        "\n",
        "        self.linears = nn.ModuleList()\n",
        "        for i in range(0, len(self.linear_dims)-1):\n",
        "            if self.params.get('dropout') > 0.0:\n",
        "                self.linears.append(nn.Dropout(p=self.params.get('dropout')))\n",
        "            linear_layer = nn.Linear(self.linear_dims[i], self.linear_dims[i+1])\n",
        "            self.init_weights(linear_layer)\n",
        "            self.linears.append(linear_layer)\n",
        "            if i == len(self.linear_dims) - 1:\n",
        "                break\n",
        "            self.linears.append(nn.ReLU())\n",
        "\n",
        "        self.to(self.device)\n",
        "\n",
        "  def init_weights(self, layer):\n",
        "    if type(layer) == nn.Linear:\n",
        "      torch.nn.init.xavier_uniform_(layer.weight)\n",
        "      layer.bias.data.fill_(0.01)\n",
        "\n",
        "  def forward(self, passage_inputs, passage_lengths, query_inputs, query_lengths):\n",
        "\n",
        "    passage_output = self.passage_network.forward(passage_inputs,passage_lengths)\n",
        "    query_output = self.query_network.forward(query_inputs,query_lengths)\n",
        "    concatenated_output = torch.cat((passage_output,query_output),dim=1)\n",
        "\n",
        "    X = concatenated_output\n",
        "\n",
        "    for l in self.linears:\n",
        "      X = l(X)\n",
        "\n",
        "    return X"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dk45-RvzIlqx"
      },
      "source": [
        "model = RankingModel(device, params_dictionary,look_up_table)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHFL3jBrwzSy",
        "outputId": "3ebbb660-05a2-40c1-bcfa-e91a77207f8f"
      },
      "source": [
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer =  torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "loss = []\n",
        "\n",
        "epochs = 200\n",
        "\n",
        "for i in range(epochs):\n",
        "  loss_batches = []\n",
        "  for batch_index,training_batch in enumerate (train_set_loader,0):\n",
        "\n",
        "      passage_input, passage_lengths, query_input, query_lengths, labels = training_batch\n",
        "      labels,p_inputs,q_inputs,p_lengths,q_lengths = Variable(labels), Variable(passage_input), Variable(query_input), Variable(passage_lengths), Variable(query_lengths)\n",
        "      optimizer.zero_grad()\n",
        "      y_pred = model.forward(p_inputs,p_lengths,q_inputs,q_lengths)\n",
        "      single_loss = loss_function(y_pred,labels).to(device)\n",
        "      single_loss.backward()\n",
        "      optimizer.step()\n",
        "      loss_batches.append(single_loss.item())\n",
        "  loss.append(np.mean(np.array(loss_batches)))\n",
        "  print(\"epoch  \" + str(i+1) + \" \" + str(loss[-1]))\n",
        "  clear_output(wait=True)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch  200 0.0005510665312713717\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "addywYG73z1Z"
      },
      "source": [
        "torch.save(model.state_dict(), 'drive/MyDrive/Models/RankingNN')"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvdSo06fD-XE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "213e8169-2f05-45df-ca9b-3e31b5f9354c"
      },
      "source": [
        "iters = [i+1 for i in range(epochs)]\n",
        "plt.plot(iters,loss)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f05544f8b90>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFBXn6ky-AA0"
      },
      "source": [
        "**Loading the Neural Net in order to make predictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0yQ7w-v9-8V",
        "outputId": "bf9989d8-e560-4ce0-be31-43f8a98a7eea"
      },
      "source": [
        "model = RankingModel(device, params_dictionary,look_up_table)\n",
        "model.load_state_dict(torch.load('drive/MyDrive/Models/RankingNN'))\n",
        "model.eval()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RankingModel(\n",
              "  (passage_network): RnnClassifier(\n",
              "    (attention): Attention(\n",
              "      (concat_linear): Linear(in_features=1024, out_features=512, bias=True)\n",
              "      (attn): Linear(in_features=512, out_features=512, bias=True)\n",
              "    )\n",
              "    (word_embeddings): Embedding(53806, 300)\n",
              "    (rnn): LSTM(300, 256, batch_first=True, bidirectional=True)\n",
              "    (linears): ModuleList(\n",
              "      (0): Linear(in_features=512, out_features=128, bias=True)\n",
              "      (1): ReLU()\n",
              "      (2): Linear(in_features=128, out_features=64, bias=True)\n",
              "      (3): ReLU()\n",
              "      (4): Linear(in_features=64, out_features=32, bias=True)\n",
              "      (5): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (query_network): RnnClassifier(\n",
              "    (attention): Attention(\n",
              "      (concat_linear): Linear(in_features=1024, out_features=512, bias=True)\n",
              "      (attn): Linear(in_features=512, out_features=512, bias=True)\n",
              "    )\n",
              "    (word_embeddings): Embedding(53806, 300)\n",
              "    (rnn): LSTM(300, 256, batch_first=True, bidirectional=True)\n",
              "    (linears): ModuleList(\n",
              "      (0): Linear(in_features=512, out_features=128, bias=True)\n",
              "      (1): ReLU()\n",
              "      (2): Linear(in_features=128, out_features=64, bias=True)\n",
              "      (3): ReLU()\n",
              "      (4): Linear(in_features=64, out_features=32, bias=True)\n",
              "      (5): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (linears): ModuleList(\n",
              "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=64, out_features=32, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=32, out_features=2, bias=True)\n",
              "    (5): ReLU()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKlHEzIBIn0Q"
      },
      "source": [
        "predictions = []\n",
        "for batch_index,training_batch in enumerate (test_set_loader,0):\n",
        "  passage_input, passage_lengths, query_input, query_lengths, labels = training_batch\n",
        "  labels,p_inputs,q_inputs,p_lengths,q_lengths = Variable(labels), Variable(passage_input), Variable(query_input), Variable(passage_lengths), Variable(query_lengths)\n",
        "  test_predictions = model.forward(p_inputs,p_lengths,q_inputs,q_lengths)\n",
        "  for t in test_predictions:\n",
        "    if(t[0] > t[1]):\n",
        "      predictions.append(-t[0])\n",
        "    else:\n",
        "      predictions.append(t[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74oJdT4fNqaR"
      },
      "source": [
        "Average_Precision(predictions,test_labels,test_query_dict,test_relevant_passages_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6Tje04lNuKB"
      },
      "source": [
        "Average_NDCG(predictions,test_labels,test_query_dict,test_relevant_passages_dict)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}